{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mounting Drive"
      ],
      "metadata": {
        "id": "Z68zTc_IoHhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0tiLXMF-jiKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yhldFzH6sqro"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Loading"
      ],
      "metadata": {
        "id": "Bgglw7GEpXI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('/content/cleaned_ratings.csv')\n",
        "anime_df = pd.read_csv('/content/cleaned_anime.csv')"
      ],
      "metadata": {
        "id": "iXcDQT8apLwa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interaction Matrix"
      ],
      "metadata": {
        "id": "G8eA1bPGpZ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate entries\n",
        "ratings= ratings.drop_duplicates(subset=['user_id', 'anime_id'])\n",
        "\n",
        "# Then proceed with creating the interaction matrix\n",
        "interaction_matrix = (\n",
        "    ratings.set_index(['user_id', 'anime_id'])['rating']\n",
        "    .unstack(fill_value=0)\n",
        ")\n",
        "\n",
        "print(interaction_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlQ5ypjZpJAb",
        "outputId": "f321bd1e-d148-46d0-9bd5-6d741def7939"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anime_id  NaN      1.0      5.0      6.0      7.0      8.0      15.0     \\\n",
            "user_id                                                                   \n",
            "1             0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "2             0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "3             0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "4             0.0      0.0      0.0     -1.0      0.0      0.0      0.0   \n",
            "5             0.0      0.0      0.0      8.0      0.0      0.0      6.0   \n",
            "...           ...      ...      ...      ...      ...      ...      ...   \n",
            "30860         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "30861         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "30862         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "30863         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "30864         NaN     10.0     -1.0      0.0      0.0      0.0      0.0   \n",
            "\n",
            "anime_id  16.0     17.0     18.0     ...  34173.0  34238.0  34239.0  34240.0  \\\n",
            "user_id                              ...                                       \n",
            "1             0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "2             0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "3             0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "4             0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "5             0.0      6.0      6.0  ...      0.0      0.0      0.0      0.0   \n",
            "...           ...      ...      ...  ...      ...      ...      ...      ...   \n",
            "30860         0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "30861         0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "30862         0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "30863         0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "30864         8.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
            "\n",
            "anime_id  34283.0  34324.0  34325.0  34349.0  34367.0  34475.0  \n",
            "user_id                                                         \n",
            "1             0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "2             0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "3             0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "4             0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "5             0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "...           ...      ...      ...      ...      ...      ...  \n",
            "30860         0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "30861         0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "30862         0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "30863         0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "30864         0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "\n",
            "[30864 rows x 9612 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding Pearson Correlation For Users"
      ],
      "metadata": {
        "id": "fn62lqDYpwH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_correlation = np.corrcoef(interaction_matrix.T)\n"
      ],
      "metadata": {
        "id": "h93EKueJpg1K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ratings Prediction Code using Pearson Correlation"
      ],
      "metadata": {
        "id": "VxnyR0LSp1F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(ratings, scores, interaction_matrix, user, item):\n",
        "    result = 0\n",
        "    denom = 0\n",
        "\n",
        "    # mean rating of the user\n",
        "    user_mean_rating = interaction_matrix.loc[user].mean()\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        similar_user = ratings[i]\n",
        "        similarity_score = scores[i]\n",
        "\n",
        "        if similar_user in interaction_matrix.index and item in interaction_matrix.columns:\n",
        "            user_rating = interaction_matrix.loc[similar_user, item]\n",
        "            similar_user_mean_rating = interaction_matrix.loc[similar_user].mean()\n",
        "            mean_centered_rating = user_rating - similar_user_mean_rating\n",
        "            result += similarity_score * mean_centered_rating\n",
        "            denom += abs(similarity_score)\n",
        "    if denom == 0:\n",
        "        return user_mean_rating\n",
        "\n",
        "    result /= denom\n",
        "    result += user_mean_rating\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "LnBhx9J9pkJ9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding Similar User Using Pearson Correlation"
      ],
      "metadata": {
        "id": "UwSXMrF6p7rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find k most similar users\n",
        "def find_similar_users(k, user, pearson_correlation, interaction_matrix):\n",
        "    k += 1\n",
        "    user_index = interaction_matrix.index.get_loc(user)\n",
        "    similarity_scores = pearson_correlation[user_index]\n",
        "    similar_users_indices = np.argsort(similarity_scores)[::-1][:k]\n",
        "    similar_users_indices = similar_users_indices[similar_users_indices != user_index]\n",
        "    similar_users = interaction_matrix.index[similar_users_indices]\n",
        "    return list(similar_users), similarity_scores[similar_users_indices]\n"
      ],
      "metadata": {
        "id": "P7XxjfqDphW0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Code"
      ],
      "metadata": {
        "id": "Xtzu8L0EpnYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 3\n",
        "item_id = 226\n",
        "k = 5\n",
        "similar_users, scores = find_similar_users(k, user_id, pearson_correlation, interaction_matrix)\n",
        "predicted_rating = prediction(similar_users, scores, interaction_matrix, user_id, item_id)\n",
        "print(\"Predicted Rating:\", predicted_rating)\n"
      ],
      "metadata": {
        "id": "BWmsNXq9pm-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f14939a-287b-4720-b1bd-b66e7cc981db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Rating: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_anime(user_id, interaction_matrix, pearson_correlation, k, anime_df, top_n=5):\n",
        "    all_anime_ids = interaction_matrix.columns\n",
        "    rated_anime_ids = interaction_matrix.loc[user_id][interaction_matrix.loc[user_id] > 0].index\n",
        "    anime_to_predict = [anime_id for anime_id in all_anime_ids if anime_id not in rated_anime_ids]\n",
        "    predictions = []\n",
        "    for anime_id in anime_to_predict:\n",
        "        similar_users, scores = find_similar_users(k, user_id, pearson_correlation, interaction_matrix)\n",
        "        predicted_rating = prediction(similar_users, scores, interaction_matrix, user_id, anime_id)\n",
        "        predictions.append((anime_id, predicted_rating))\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_anime_ids = [anime_id for anime_id, _ in predictions[:top_n]]\n",
        "\n",
        "    recommended_anime = anime_df[anime_df['anime_id'].isin(top_anime_ids)]\n",
        "\n",
        "    return recommended_anime\n",
        "\n",
        "user_id = 3\n",
        "k = 5\n",
        "top_n = 5\n",
        "\n",
        "recommended_anime = recommend_anime(user_id, interaction_matrix, pearson_correlation, k, anime_df, top_n)\n",
        "print(\"Top Recommended Anime for User\", user_id)\n",
        "print(recommended_anime[['anime_id', 'name', 'genre', 'type', 'episodes', 'rating', 'members']])"
      ],
      "metadata": {
        "id": "xD9rImdFprCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846b9ade-ba4e-4eb4-deee-3bec325bfc55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Recommended Anime for User 3\n",
            "      anime_id                             name  \\\n",
            "22           1                     Cowboy Bebop   \n",
            "152          5  Cowboy Bebop: Tengoku no Tobira   \n",
            "214          6                           Trigun   \n",
            "2094         7               Witch Hunter Robin   \n",
            "\n",
            "                                                  genre   type  episodes  \\\n",
            "22      Action, Adventure, Comedy, Drama, Sci-Fi, Space     TV      26.0   \n",
            "152               Action, Drama, Mystery, Sci-Fi, Space  Movie       1.0   \n",
            "214                              Action, Comedy, Sci-Fi     TV      26.0   \n",
            "2094  Action, Drama, Magic, Mystery, Police, Superna...     TV      26.0   \n",
            "\n",
            "      rating  members  \n",
            "22      8.82   486824  \n",
            "152     8.40   137636  \n",
            "214     8.32   283069  \n",
            "2094    7.36    64905  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate Loss Between Actual And predicted Values"
      ],
      "metadata": {
        "id": "coaDl8HyqfHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def recommend_anime_with_metrics(user_id, interaction_matrix, pearson_correlation, k, anime_df, ratings_df, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend top_n anime for a given user and calculate MSE and MAE.\n",
        "\n",
        "    Parameters:\n",
        "        user_id: ID of the user.\n",
        "        interaction_matrix: User-item interaction matrix.\n",
        "        pearson_correlation: Precomputed Pearson correlation matrix.\n",
        "        k: Number of similar users to consider.\n",
        "        anime_df: DataFrame containing anime details.\n",
        "        ratings_df: DataFrame containing user ratings.\n",
        "        top_n: Number of anime recommendations to return (default: 5).\n",
        "\n",
        "    Returns:\n",
        "        recommended_anime: DataFrame of recommended anime.\n",
        "        mse: Mean Squared Error of predictions.\n",
        "        mae: Mean Absolute Error of predictions.\n",
        "    \"\"\"\n",
        "    all_anime_ids = interaction_matrix.columns\n",
        "    rated_anime_ids = interaction_matrix.loc[user_id][interaction_matrix.loc[user_id] > 0].index\n",
        "    anime_to_predict = [anime_id for anime_id in all_anime_ids if anime_id not in rated_anime_ids]\n",
        "\n",
        "    predictions = []\n",
        "    actual_ratings = []\n",
        "\n",
        "    for anime_id in anime_to_predict:\n",
        "        # Find similar users and their scores\n",
        "        similar_users, scores = find_similar_users(k, user_id, pearson_correlation, interaction_matrix)\n",
        "\n",
        "        # Predict the rating for the current anime\n",
        "        predicted_rating = prediction(similar_users, scores, interaction_matrix, user_id, anime_id)\n",
        "        predictions.append((anime_id, predicted_rating))\n",
        "\n",
        "        # Retrieve the actual rating if it exists\n",
        "        actual_rating = ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['anime_id'] == anime_id)]\n",
        "        if not actual_rating.empty:\n",
        "            actual_ratings.append(actual_rating['rating'].values[0])\n",
        "\n",
        "    # Sort predictions by predicted rating\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top-n recommended anime\n",
        "    top_anime_ids = [anime_id for anime_id, _ in predictions[:top_n]]\n",
        "    recommended_anime = anime_df[anime_df['anime_id'].isin(top_anime_ids)]\n",
        "\n",
        "    # Filter actual ratings and predicted ratings for MSE/MAE calculation\n",
        "    top_actual_ratings = []\n",
        "    top_predicted_ratings = []\n",
        "\n",
        "    for anime_id, predicted_rating in predictions[:top_n]:\n",
        "        actual_rating = ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['anime_id'] == anime_id)]\n",
        "        if not actual_rating.empty:\n",
        "            top_actual_ratings.append(actual_rating['rating'].values[0])\n",
        "            top_predicted_ratings.append(predicted_rating)\n",
        "\n",
        "    # Calculate MSE and MAE\n",
        "    if top_actual_ratings:\n",
        "        mse = mean_squared_error(top_actual_ratings, top_predicted_ratings)\n",
        "        mae = mean_absolute_error(top_actual_ratings, top_predicted_ratings)\n",
        "    else:\n",
        "        mse = mae = None  # No actual ratings available for comparison\n",
        "\n",
        "    return recommended_anime, mse, mae\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "user_id = 3\n",
        "k = 5\n",
        "top_n = 5\n",
        "\n",
        "recommended_anime, mse, mae = recommend_anime_with_metrics(user_id, interaction_matrix, pearson_correlation, k, anime_df, ratings, top_n)\n",
        "\n",
        "print(\"Top Recommended Anime for User\", user_id)\n",
        "print(recommended_anime[['anime_id', 'name', 'genre', 'type', 'episodes', 'rating', 'members']])\n",
        "\n",
        "if mse is not None and mae is not None:\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "else:\n",
        "    print(\"No actual ratings available to calculate MSE and MAE.\")\n"
      ],
      "metadata": {
        "id": "Dw2Ns1j6qdwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ca4613-4262-411a-8269-f15f6fe8f376"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Recommended Anime for User 3\n",
            "      anime_id                             name  \\\n",
            "22           1                     Cowboy Bebop   \n",
            "152          5  Cowboy Bebop: Tengoku no Tobira   \n",
            "214          6                           Trigun   \n",
            "2094         7               Witch Hunter Robin   \n",
            "\n",
            "                                                  genre   type  episodes  \\\n",
            "22      Action, Adventure, Comedy, Drama, Sci-Fi, Space     TV      26.0   \n",
            "152               Action, Drama, Mystery, Sci-Fi, Space  Movie       1.0   \n",
            "214                              Action, Comedy, Sci-Fi     TV      26.0   \n",
            "2094  Action, Drama, Magic, Mystery, Police, Superna...     TV      26.0   \n",
            "\n",
            "      rating  members  \n",
            "22      8.82   486824  \n",
            "152     8.40   137636  \n",
            "214     8.32   283069  \n",
            "2094    7.36    64905  \n",
            "No actual ratings available to calculate MSE and MAE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "RdKs8QM_oMV2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p9e1orRUyFbx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "S7WYC_8yoQcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anime_df = pd.read_csv('/content/cleaned_anime.csv')\n",
        "ratings_df = pd.read_csv('/content/cleaned_ratings.csv')"
      ],
      "metadata": {
        "id": "CPFsoD2TYXau"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Null and Unrated Animes"
      ],
      "metadata": {
        "id": "-1ZWaNdSoR1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Is GPU available:\", tf.test.is_gpu_available())\n",
        "print(\"Available devices:\", tf.config.list_physical_devices())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HijiXu-n66J",
        "outputId": "103df2dd-2413-45ef-ea8a-2476f22ce5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-e2c7c17b0980>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is GPU available: False\n",
            "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = ratings_df[ratings_df.rating.notna()]\n",
        "ratings_df = ratings_df[ratings_df['rating'] > 0]"
      ],
      "metadata": {
        "id": "lKipiMXjZDm0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing\n",
        "Encoding User ids and animes id and also normalizing ratings"
      ],
      "metadata": {
        "id": "Hu17O-broX9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode user_id and anime_id\n",
        "user_encoder = LabelEncoder()\n",
        "anime_encoder = LabelEncoder()\n",
        "\n",
        "ratings_df['user_id'] = user_encoder.fit_transform(ratings_df['user_id'])\n",
        "ratings_df['anime_id'] = anime_encoder.fit_transform(ratings_df['anime_id'])\n",
        "\n",
        "num_users = ratings_df['user_id'].nunique()\n",
        "num_animes = ratings_df['anime_id'].nunique()\n",
        "\n",
        "# Normalize ratings\n",
        "ratings_df['rating'] = ratings_df['rating'] / 10.0  # Scale ratings to [0, 1]\n",
        "\n",
        "# Train-test split\n",
        "train, test = train_test_split(ratings_df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Neural network inputs\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "anime_input = Input(shape=(1,), name='anime_input')\n",
        "\n",
        "# Embedding layers\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=50, name='user_embedding')(user_input)\n",
        "anime_embedding = Embedding(input_dim=num_animes, output_dim=50, name='anime_embedding')(anime_input)\n",
        "\n",
        "# Flatten embeddings\n",
        "user_flat = Flatten()(user_embedding)\n",
        "anime_flat = Flatten()(anime_embedding)\n",
        "\n",
        "# Concatenate embeddings\n",
        "concat = Concatenate()([user_flat, anime_flat])"
      ],
      "metadata": {
        "id": "x1Gj3jZajMPZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nueral Network Architechture"
      ],
      "metadata": {
        "id": "IoKt2knxolfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode user_id and anime_id\n",
        "user_encoder = LabelEncoder()\n",
        "anime_encoder = LabelEncoder()\n",
        "\n",
        "ratings_df['user_id'] = user_encoder.fit_transform(ratings_df['user_id'])\n",
        "ratings_df['anime_id'] = anime_encoder.fit_transform(ratings_df['anime_id'])\n",
        "\n",
        "num_users = ratings_df['user_id'].nunique()\n",
        "num_animes = ratings_df['anime_id'].nunique()\n",
        "\n",
        "# Normalize ratings\n",
        "ratings_df['rating'] = ratings_df['rating'] / 10.0  # Scale ratings to [0, 1]\n",
        "\n",
        "# Train-test split\n",
        "train, test = train_test_split(ratings_df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Neural network inputs\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "anime_input = Input(shape=(1,), name='anime_input')\n",
        "\n",
        "# Embedding layers\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=50, name='user_embedding')(user_input)\n",
        "anime_embedding = Embedding(input_dim=num_animes, output_dim=50, name='anime_embedding')(anime_input)\n",
        "\n",
        "# Flatten embeddings\n",
        "user_flat = Flatten()(user_embedding)\n",
        "anime_flat = Flatten()(anime_embedding)\n",
        "\n",
        "# Concatenate embeddings\n",
        "concat = Concatenate()([user_flat, anime_flat])\n",
        "\n",
        "# Fully connected layers\n",
        "dense1 = Dense(128, activation='relu')(concat)\n",
        "dropout1 = Dropout(0.3)(dense1)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "dropout2 = Dropout(0.2)(dense2)\n",
        "output = Dense(1, activation='sigmoid')(dense2)  # Sigmoid to predict normalized ratings\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=[user_input, anime_input], outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "with tf.device('/GPU:0'):\n",
        "  history = model.fit(\n",
        "    [train['user_id'], train['anime_id']], train['rating'],\n",
        "    validation_data=([test['user_id'], test['anime_id']], test['rating']),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_mae = model.evaluate([test['user_id'], test['anime_id']], test['rating'])\n",
        "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('anime_recommendation_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhSvVkSg4SR",
        "outputId": "70f6510f-d43d-4870-bf08-cb5b97544eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 3ms/step - loss: 0.0161 - mae: 0.0967 - val_loss: 0.0139 - val_mae: 0.0896\n",
            "Epoch 2/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0870 - val_loss: 0.0135 - val_mae: 0.0873\n",
            "Epoch 3/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0845 - val_loss: 0.0133 - val_mae: 0.0859\n",
            "Epoch 4/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0820 - val_loss: 0.0131 - val_mae: 0.0860\n",
            "Epoch 5/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0798 - val_loss: 0.0130 - val_mae: 0.0851\n",
            "Epoch 6/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0778 - val_loss: 0.0129 - val_mae: 0.0852\n",
            "Epoch 7/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0759 - val_loss: 0.0129 - val_mae: 0.0846\n",
            "Epoch 8/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0743 - val_loss: 0.0129 - val_mae: 0.0846\n",
            "Epoch 9/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0728 - val_loss: 0.0130 - val_mae: 0.0855\n",
            "Epoch 10/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0715 - val_loss: 0.0131 - val_mae: 0.0855\n",
            "Epoch 11/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0704 - val_loss: 0.0133 - val_mae: 0.0851\n",
            "Epoch 12/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0693 - val_loss: 0.0131 - val_mae: 0.0847\n",
            "Epoch 13/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0683 - val_loss: 0.0132 - val_mae: 0.0853\n",
            "Epoch 14/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0674 - val_loss: 0.0132 - val_mae: 0.0858\n",
            "Epoch 15/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - loss: 0.0088 - mae: 0.0667 - val_loss: 0.0137 - val_mae: 0.0875\n",
            "Epoch 16/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0660 - val_loss: 0.0135 - val_mae: 0.0864\n",
            "Epoch 17/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0654 - val_loss: 0.0137 - val_mae: 0.0865\n",
            "Epoch 18/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0648 - val_loss: 0.0135 - val_mae: 0.0858\n",
            "Epoch 19/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0643 - val_loss: 0.0137 - val_mae: 0.0871\n",
            "Epoch 20/20\n",
            "\u001b[1m178223/178223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0638 - val_loss: 0.0137 - val_mae: 0.0863\n",
            "\u001b[1m19803/19803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: 0.0137 - mae: 0.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss (MSE): 0.0137\n",
            "Test MAE: 0.0863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing Error of predicted values mean with Original vlaues mean"
      ],
      "metadata": {
        "id": "nd45jsxUosEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_mean = train['rating'].mean()\n",
        "baseline_rmse = np.sqrt(np.mean((test['rating'] - global_mean)**2))\n",
        "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aGfbEsuAZS5",
        "outputId": "ab8d275b-72a9-401f-9fc5-cd61d214eb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline RMSE: 0.3761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recommending Animes for A single User"
      ],
      "metadata": {
        "id": "XfXg-VBso4dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model (if you have already saved it)\n",
        "from keras.losses import mean_squared_error as mse\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the model, explicitly registering the mse function\n",
        "model = load_model('/content/Latest Model.h5', custom_objects={'mse': mse})\n",
        "\n",
        "\n",
        "# Select a user for recommendations\n",
        "selected_user_id = 3  # Example: choose the user_id for which you want recommendations\n",
        "\n",
        "# Get all anime IDs (you can change the range if you have a smaller or larger dataset)\n",
        "anime_ids = np.arange(num_animes)  # From 0 to num_animes-1, as anime_id is encoded from 0 to num_animes-1\n",
        "\n",
        "# Predict ratings for all animes for the selected user\n",
        "predicted_ratings = model.predict([np.full_like(anime_ids, selected_user_id), anime_ids])\n",
        "\n",
        "# Create a DataFrame with predicted ratings and corresponding anime IDs\n",
        "predicted_df = pd.DataFrame({\n",
        "    'anime_id': anime_ids,\n",
        "    'predicted_rating': predicted_ratings.flatten()\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by predicted_rating in descending order (top rated animes first)\n",
        "top_10_animes = predicted_df.sort_values(by='predicted_rating', ascending=False).head(10)\n",
        "\n",
        "# Get the anime details for the top 10 animes\n",
        "recommended_animes = anime_df[anime_df['anime_id'].isin(top_10_animes['anime_id'])]\n",
        "\n",
        "# Display the recommended animes\n",
        "print(f\"Top 10 anime recommendations for User {selected_user_id}:\")\n",
        "print(recommended_animes[['anime_id', 'name', 'genre', 'type', 'episodes', 'rating']])\n"
      ],
      "metadata": {
        "id": "7wplLPqN2F0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d34b5a-1609-471e-a247-20e053bb439b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Top 10 anime recommendations for User 3:\n",
            "      anime_id                                               name  \\\n",
            "905        540                  Tenchi Muyou! Ryououki 2nd Season   \n",
            "917       1376                            Ojamajo Doremi Na-i-sho   \n",
            "1905      6288  Mobile Suit Gundam 00 The Movie: A Wakening of...   \n",
            "2486      1417                      Lupin III: Moeyo Zantetsuken!   \n",
            "3077      6884                  Ookami to Koushinryou II Specials   \n",
            "6093      6875                                           Iron Man   \n",
            "\n",
            "                                              genre     type  episodes  rating  \n",
            "905   Action, Comedy, Harem, Sci-Fi, Shounen, Space      OVA       6.0    7.78  \n",
            "917                  Comedy, Fantasy, Magic, Shoujo      OVA      13.0    7.77  \n",
            "1905                   Action, Mecha, Sci-Fi, Space    Movie       1.0    7.41  \n",
            "2486             Action, Adventure, Comedy, Shounen  Special       1.0    7.25  \n",
            "3077                                        Fantasy  Special       2.0    7.09  \n",
            "6093                           Action, Drama, Mecha       TV      12.0    6.25  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAP@K AND R@K"
      ],
      "metadata": {
        "id": "UFZLa8xIo9VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics_at_k(model, ratings_df, anime_df, user_ids, k=10):\n",
        "    \"\"\"\n",
        "    Calculate MAP@K and Recall@K for a list of users.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained recommendation model.\n",
        "        ratings_df: DataFrame with user_id, anime_id, and actual ratings.\n",
        "        anime_df: DataFrame with anime details (including anime_id).\n",
        "        user_ids: List of user IDs to evaluate.\n",
        "        k: Number of recommendations to consider (default: 10).\n",
        "\n",
        "    Returns:\n",
        "        map_k: Mean Average Precision at K.\n",
        "        recall_k: Recall at K.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import average_precision_score\n",
        "\n",
        "    map_k = 0\n",
        "    recall_k = 0\n",
        "    relevant_users_count = 0\n",
        "\n",
        "    for user_id in user_ids:\n",
        "        # Get the actual relevant items for the user (rating >= threshold, e.g., 6)\n",
        "        user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
        "        relevant_items = user_ratings[user_ratings['rating'] >= 0.6]['anime_id'].values  # Normalize threshold for relevant ratings\n",
        "\n",
        "        if len(relevant_items) == 0:\n",
        "            continue  # Skip users without relevant items\n",
        "\n",
        "        relevant_users_count += 1\n",
        "\n",
        "        # Predict ratings for all anime for this user\n",
        "        # Ensure anime_ids are within the valid range (encoded values)\n",
        "        anime_ids = anime_df['anime_id'].values\n",
        "        predicted_ratings = model.predict([np.full_like(anime_ids, user_id), anime_ids], verbose=0).flatten()\n",
        "\n",
        "        # Rank the anime by predicted rating\n",
        "        top_k_anime_ids = anime_ids[np.argsort(-predicted_ratings)[:k]]\n",
        "\n",
        "        # Calculate precision at K for this user\n",
        "        is_relevant = np.isin(top_k_anime_ids, relevant_items).astype(int)\n",
        "        average_precision = average_precision_score(is_relevant, np.arange(1, len(is_relevant) + 1))\n",
        "\n",
        "        # Add to MAP@K\n",
        "        map_k += average_precision\n",
        "\n",
        "        # Calculate Recall@K\n",
        "        recall_k += is_relevant.sum() / len(relevant_items)\n",
        "\n",
        "    # Compute the average metrics\n",
        "    if relevant_users_count > 0:\n",
        "        map_k /= relevant_users_count\n",
        "        recall_k /= relevant_users_count\n",
        "    else:\n",
        "        map_k = recall_k = 0  # Handle case where no relevant items are found\n",
        "\n",
        "    return map_k, recall_k\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "selected_users = ratings_df['user_id'].unique()[:10]  # Select the first 10 unique users\n",
        "map_10, recall_10 = calculate_metrics_at_k(model, ratings_df, anime_df, selected_users, k=10)\n",
        "\n",
        "print(f\"MAP@10: {map_10:.4f}\")\n",
        "print(f\"Recall@10: {recall_10:.4f}\")\n"
      ],
      "metadata": {
        "id": "VFR7In8NkCK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommend_anime(user_id, interaction_matrix, pearson_correlation, k, anime_df, num_animes, model, top_n=5, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Hybrid recommendation system combining Neural Network and User-Based Collaborative Filtering (UBCF).\n",
        "    \"\"\"\n",
        "    # Step 1: Predict ratings using the neural network model\n",
        "    anime_ids = np.arange(num_animes)  # All anime IDs (from 0 to num_animes-1)\n",
        "    predicted_ratings_nn = model.predict([np.full_like(anime_ids, user_id), anime_ids]).flatten()\n",
        "\n",
        "    # Step 2: Predict ratings using User-Based Collaborative Filtering (UBCF)\n",
        "    all_anime_ids = interaction_matrix.columns\n",
        "    rated_anime_ids = interaction_matrix.loc[user_id][interaction_matrix.loc[user_id] > 0].index\n",
        "    anime_to_predict = [anime_id for anime_id in all_anime_ids if anime_id not in rated_anime_ids]\n",
        "\n",
        "    predictions_ubcf = []\n",
        "    for anime_id in anime_to_predict:\n",
        "        # Find similar users and their scores\n",
        "        similar_users, scores = find_similar_users(k, user_id, pearson_correlation, interaction_matrix)\n",
        "        predicted_rating_ubcf = prediction(similar_users, scores, interaction_matrix, user_id, anime_id)\n",
        "        predictions_ubcf.append((anime_id, predicted_rating_ubcf))\n",
        "\n",
        "    predictions_ubcf.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_anime_ids_ubcf = [anime_id for anime_id, _ in predictions_ubcf[:top_n]]\n",
        "\n",
        "    # Step 3: Combine the NN and UBCF predictions\n",
        "    combined_predictions = []\n",
        "\n",
        "    # Map anime_id to the corresponding index in predicted_ratings_nn\n",
        "    anime_id_to_index = {anime_id: idx for idx, anime_id in enumerate(anime_ids)}\n",
        "\n",
        "    for anime_id in anime_to_predict:\n",
        "        # Map anime_id to the correct index in predicted_ratings_nn\n",
        "        nn_pred_idx = anime_id_to_index.get(anime_id, -1)  # Get the index, default to -1 if not found\n",
        "        if nn_pred_idx != -1:\n",
        "            nn_pred = predicted_ratings_nn[nn_pred_idx]\n",
        "        else:\n",
        "            nn_pred = 0  # Default to 0 if the anime_id is not found in predicted ratings\n",
        "\n",
        "        # Find UBCF prediction (if available)\n",
        "        ubcf_pred = next((rating for aid, rating in predictions_ubcf if aid == anime_id), 0)\n",
        "\n",
        "        # Combine the predictions (you can adjust the alpha parameter to weight NN vs UBCF)\n",
        "        combined_rating = alpha * nn_pred + (1 - alpha) * ubcf_pred\n",
        "        combined_predictions.append((anime_id, combined_rating))\n",
        "\n",
        "    # Sort by combined ratings and get the top N recommendations\n",
        "    combined_predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_anime_ids_combined = [anime_id for anime_id, _ in combined_predictions[:top_n]]\n",
        "\n",
        "    # Step 4: Get the anime details for the top N recommendations\n",
        "    recommended_anime = anime_df[anime_df['anime_id'].isin(top_anime_ids_combined)]\n",
        "\n",
        "    return recommended_anime\n",
        "\n",
        "# Example Usage\n",
        "selected_user_id = 3\n",
        "k = 5\n",
        "top_n = 5\n",
        "alpha = 0.6  # You can adjust this parameter for the hybrid approach\n",
        "\n",
        "recommended_anime = hybrid_recommend_anime(selected_user_id, interaction_matrix, pearson_correlation, k, anime_df, num_animes, model, top_n, alpha)\n",
        "\n",
        "# Display the recommended anime\n",
        "print(f\"Top {top_n} Hybrid Anime Recommendations for User {selected_user_id}:\")\n",
        "print(recommended_anime[['anime_id', 'name', 'genre', 'type', 'episodes', 'rating']])\n"
      ],
      "metadata": {
        "id": "XMXA1TWlnkTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bce9d4-e3a3-4aeb-81b5-9e24f8777a4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Top 5 Hybrid Anime Recommendations for User 3:\n",
            "      anime_id                             name  \\\n",
            "22           1                     Cowboy Bebop   \n",
            "152          5  Cowboy Bebop: Tengoku no Tobira   \n",
            "214          6                           Trigun   \n",
            "2094         7               Witch Hunter Robin   \n",
            "\n",
            "                                                  genre   type  episodes  \\\n",
            "22      Action, Adventure, Comedy, Drama, Sci-Fi, Space     TV      26.0   \n",
            "152               Action, Drama, Mystery, Sci-Fi, Space  Movie       1.0   \n",
            "214                              Action, Comedy, Sci-Fi     TV      26.0   \n",
            "2094  Action, Drama, Magic, Mystery, Police, Superna...     TV      26.0   \n",
            "\n",
            "      rating  \n",
            "22      8.82  \n",
            "152     8.40  \n",
            "214     8.32  \n",
            "2094    7.36  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLh7GsZ5ux29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}